{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af491c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATE EXPERT ANSWERS\n",
    "\n",
    "answer_instructions = \"\"\"You are a culinary expert being interviewed.\n",
    "\n",
    "Analyst focus: {goals}\n",
    "\n",
    "Use ONLY the provided sources to answer: {context}\n",
    "\n",
    "Guidelines:\n",
    "1. Base answers on evidence from provided sources\n",
    "2. Cite sources using [1], [2], etc.\n",
    "3. Be specific and practical\n",
    "4. Include cooking tips\n",
    "5. Keep response concise (max 500 words)\n",
    "\n",
    "Provide accurate, helpful culinary information.\"\"\"\n",
    "\n",
    "def generate_answer(state: InterviewState):\n",
    "    analyst = state[\"analyst\"]\n",
    "    messages = state[\"messages\"]\n",
    "    context = state[\"context\"]\n",
    "\n",
    "    # Limit context\n",
    "    context_text = '\\n'.join(context)\n",
    "    if len(context_text) > 3000:\n",
    "        context_text = context_text[:3000] + \"...[truncated]\"\n",
    "\n",
    "    system_message = answer_instructions.format(goals=analyst.persona, context=context_text)\n",
    "    answer = llm.invoke(\n",
    "        [SystemMessage(content=system_message)] + messages,\n",
    "        max_tokens=1000  # Limit response\n",
    "    )\n",
    "    answer.name = \"culinary_expert\"\n",
    "\n",
    "    return {\"messages\": [answer]}\n",
    "\n",
    "def save_interview(state: InterviewState):\n",
    "    messages = state[\"messages\"]\n",
    "    interview = get_buffer_string(messages)\n",
    "    return {\"interview\": interview}\n",
    "\n",
    "def route_messages(state: InterviewState, name: str = \"culinary_expert\"):\n",
    "    messages = state[\"messages\"]\n",
    "    max_num_turns = state.get('max_num_turns', 2)\n",
    "\n",
    "    num_responses = len([m for m in messages if isinstance(m, AIMessage) and m.name == name])\n",
    "\n",
    "    if num_responses >= max_num_turns:\n",
    "        return 'save_interview'\n",
    "\n",
    "    if len(messages) >= 2:\n",
    "        last_question = messages[-2]\n",
    "        if \"Thank you so much for your help\" in last_question.content:\n",
    "            return 'save_interview'\n",
    "\n",
    "    return \"ask_question\"\n",
    "\n",
    "print(\" Answer generation system ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1541b7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUILD INTERVIEW GRAPH\n",
    "\n",
    "interview_builder = StateGraph(InterviewState)\n",
    "interview_builder.add_node(\"ask_question\", generate_question)\n",
    "interview_builder.add_node(\"search_web\", search_web)\n",
    "interview_builder.add_node(\"search_wikipedia\", search_wikipedia)\n",
    "interview_builder.add_node(\"answer_question\", generate_answer)\n",
    "interview_builder.add_node(\"save_interview\", save_interview)\n",
    "\n",
    "interview_builder.add_edge(START, \"ask_question\")\n",
    "interview_builder.add_edge(\"ask_question\", \"search_web\")\n",
    "interview_builder.add_edge(\"ask_question\", \"search_wikipedia\")\n",
    "interview_builder.add_edge(\"search_web\", \"answer_question\")\n",
    "interview_builder.add_edge(\"search_wikipedia\", \"answer_question\")\n",
    "interview_builder.add_conditional_edges(\"answer_question\", route_messages, [\"ask_question\", \"save_interview\"])\n",
    "interview_builder.add_edge(\"save_interview\", END)\n",
    "\n",
    "interview_graph = interview_builder.compile()\n",
    "\n",
    "print(\" Interview graph compiled!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
